{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pymongo\n",
    "from urllib.parse import quote_plus as quote\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключимся к нашей коллекции\n",
    "\n",
    "with open('../env/credsw.yaml', 'r') as file:\n",
    "    creds_dict = yaml.safe_load(file)\n",
    "    \n",
    "url = 'mongodb://{user}:{pw}@{hosts}/?{rs}&authSource={auth_src}&{am}&tls=true&tlsCAFile={cert_file}'.format(\n",
    "    user=creds_dict['username'],\n",
    "    pw=quote(creds_dict['password']),\n",
    "    hosts=creds_dict['host'],\n",
    "    rs='replicaSet=rs01',\n",
    "    auth_src=creds_dict['database'],\n",
    "    am='authMechanism=DEFAULT',\n",
    "    cert_file='../env/root.crt'\n",
    "    )\n",
    "\n",
    "dbs = pymongo.MongoClient(url)\n",
    "\n",
    "db = dbs[creds_dict['database']]\n",
    "\n",
    "collection = db['initial_dataset']\n",
    "unique_collection = db['unique_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выгрузим данные из коллекции\n",
    "pipeline = [{ \"$unwind\" : \"$data_result.boxes\" },\n",
    "            {\"$project\":{\n",
    "                \"size\": \"$data_result.boxes.size\",\n",
    "                \"stacking\": \"$data_result.boxes.stacking\",\n",
    "                \"turnover\": \"$data_result.boxes.turnover\",\n",
    "                \"loading_size\": \"$data_result.cargo_space.loading_size\",\n",
    "                \"filling_space_percent\": \"$data_result.cargo_space.calculation_info.filling_space_percent\"\n",
    "                }},\n",
    "            {\"$group\": {\"_id\": \"$_id\",\n",
    "                        \"loading_size\": {\"$first\":\"$loading_size\"},\n",
    "                        \"filling_space_percent\": {\"$first\":\"$filling_space_percent\"},\n",
    "                        \"boxes\": {\n",
    "                            \"$push\":  {\n",
    "                                \"size\": \"$size\",\n",
    "                                \"stacking\": \"$stacking\",\n",
    "                                \"turnover\": \"$turnover\"                           \n",
    "                            }\n",
    "                            \n",
    "                        }\n",
    "            }\n",
    "            }\n",
    "            ]\n",
    "result = collection.aggregate(pipeline)\n",
    "dataset = [i for i in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_is_hash(box): #box_i = dataset[0]['boxes'][i]\n",
    "    if box['turnover']:\n",
    "        size_lst = sorted([x for x in box['size_scale'].values()])\n",
    "    else:\n",
    "        size_lst = [box['size_scale']['height'],\n",
    "                    min(box['size_scale']['width'], box['size_scale']['length']),\n",
    "                    max(box['size_scale']['width'], box['size_scale']['length'])]\n",
    "    hash_object = hashlib.md5(\n",
    "        ('h'+str(size_lst[0])+\\\n",
    "         'w'+str(size_lst[1])+\\\n",
    "         'l'+str(size_lst[2])+\\\n",
    "         's'+str(box['stacking'])+\\\n",
    "         't'+str(box['turnover'])\n",
    "        ).encode())\n",
    "    return hash_object.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_cont(loading_size):\n",
    "    hash_object = hashlib.md5(\n",
    "        ('h'+str(loading_size['height'])+\\\n",
    "         'w'+str(loading_size['width'])+\\\n",
    "         'l'+str(loading_size['length'])\n",
    "        ).encode())\n",
    "    return hash_object.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_item(item):\n",
    "    loading_size = item['loading_size']\n",
    "    norm_base = max(loading_size['width'], loading_size['height'], loading_size['length'])\n",
    "    item['loading_size_scale'] = {k: round(v*100/norm_base,2) for k,v in loading_size.items()}\n",
    "    for box in item['boxes']:\n",
    "        box_size = box['size']\n",
    "        box['size_scale'] = {k: round(v*100/norm_base,2) for k,v in box_size.items()}\n",
    "        box['hash'] = as_is_hash(box)\n",
    "    hash_object = hashlib.md5(\n",
    "        (hash_cont(loading_size) + '_' + \\\n",
    "        ','.join(sorted([box['hash'] for box in item['boxes']]))).encode()\n",
    "    )\n",
    "    item['hash'] = hash_object.hexdigest()\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_scaled = [scale_item(item) for item in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_scaled) # total containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({x['hash'] for x in dataset_scaled}) # Уникальных контейнеро-наполнений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_item(item):\n",
    "    result = dict()\n",
    "    result['hash'] = item['hash']\n",
    "    result['filling_space_percent'] = item['filling_space_percent']\n",
    "    result['loading_size_scale'] = item['loading_size_scale']\n",
    "    boxes = list()\n",
    "    for box in item['boxes']:\n",
    "        boxes.append(\n",
    "            {'hash': box['hash'],\n",
    "             'size_scale': box['size_scale'],\n",
    "             'volume':  box['size_scale']['width'] * box['size_scale']['height'] * box['size_scale']['length'],\n",
    "             'turnover': box['turnover'],\n",
    "             'stacking': box['stacking']\n",
    "             }\n",
    "        )\n",
    "    result['boxes'] = sorted(boxes, key = lambda x: x['volume'], reverse = True)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cleaned = [clean_item(item) for item in dataset_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset_cleaned:\n",
    "    result = unique_collection.update_one(\n",
    "        {'_id': item['hash']},\n",
    "        {'$set': {'filling_space_percent': item['filling_space_percent'],\n",
    "                  'loading_size_scale': item['loading_size_scale'],\n",
    "                  'boxes':item['boxes']                                    \n",
    "                  }\n",
    "         },\n",
    "        upsert=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
