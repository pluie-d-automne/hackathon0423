{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyMongo in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from pyMongo) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyyaml\n",
    "%pip install pyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pymongo\n",
    "from urllib.parse import quote_plus as quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключимся к нашей коллекции\n",
    "\n",
    "with open('../env/creds.yaml', 'r') as file:\n",
    "    creds_dict = yaml.safe_load(file)\n",
    "    \n",
    "url = 'mongodb://{user}:{pw}@{hosts}/?{rs}&authSource={auth_src}&{am}&tls=true&tlsCAFile={cert_file}'.format(\n",
    "    user=creds_dict['username'],\n",
    "    pw=quote(creds_dict['password']),\n",
    "    hosts=creds_dict['host'],\n",
    "    rs='replicaSet=rs01',\n",
    "    auth_src=creds_dict['database'],\n",
    "    am='authMechanism=DEFAULT',\n",
    "    cert_file='../env/root.crt'\n",
    "    )\n",
    "\n",
    "dbs = pymongo.MongoClient(url)\n",
    "\n",
    "db = dbs[creds_dict['database']]\n",
    "\n",
    "collection = db['initial_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример aggregation pipeline - чтобы достать только нужные поля из Mongo\n",
    "pipeline = [{ \"$unwind\" : \"$data_result.boxes\" },\n",
    "            {\"$project\":{\n",
    "                \"mass\": \"$data_result.boxes.mass\",\n",
    "                \"size\": \"$data_result.boxes.size\",\n",
    "                \"stacking\": \"$data_result.boxes.stacking\",\n",
    "                \"turnover\": \"$data_result.boxes.turnover\",\n",
    "                \"stacking_limit\": \"$data_result.boxes.stacking_limit\",\n",
    "                \"loading_size\": \"$data_result.cargo_space.loading_size\",\n",
    "                \"density_percent\": \"$data_result.cargo_space.calculation_info.density_percent\",\n",
    "                \"filling_space_percent\": \"$data_result.cargo_space.calculation_info.filling_space_percent\",\n",
    "                }},\n",
    "            {\"$group\": {\"_id\": \"$_id\",\n",
    "                        \"loading_size\": {\"$first\":\"$loading_size\"},\n",
    "                        \"density_percent\": {\"$first\":\"$density_percent\"},\n",
    "                        \"filling_space_percent\": {\"$first\":\"$filling_space_percent\"},\n",
    "                        \"boxes\": {\n",
    "                            \"$push\":  {\n",
    "                                \"mass\": \"$mass\",\n",
    "                                \"size\": \"$size\",\n",
    "                                \"stacking\": \"$stacking\",\n",
    "                                \"turnover\": \"$turnover\",\n",
    "                                \"stacking_limit\": \"$stacking_limit\"                               \n",
    "                            }\n",
    "                            \n",
    "                        }\n",
    "            }\n",
    "            }\n",
    "            ]\n",
    "result = collection.aggregate(pipeline)\n",
    "#item = result.next()\n",
    "#print(item)\n",
    "dataset = [i for i in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6427400ea78245bedd47ac48'),\n",
       " 'loading_size': {'width': 2352.0, 'height': 2393.0, 'length': 5898.0},\n",
       " 'density_percent': 75.40325,\n",
       " 'filling_space_percent': 51.77125,\n",
       " 'boxes': [{'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 705.0,\n",
       "   'size': {'width': 548.0, 'height': 587.0, 'length': 1300.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 100.0,\n",
       "   'size': {'width': 132.0, 'height': 395.0, 'length': 2213.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 312.0,\n",
       "   'size': {'width': 196.0, 'height': 885.0, 'length': 1491.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1098.0,\n",
       "   'size': {'width': 404.0, 'height': 885.0, 'length': 1856.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1098.0,\n",
       "   'size': {'width': 404.0, 'height': 885.0, 'length': 1856.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1098.0,\n",
       "   'size': {'width': 404.0, 'height': 885.0, 'length': 1856.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0},\n",
       "  {'mass': 1054.0,\n",
       "   'size': {'width': 384.0, 'height': 885.0, 'length': 1876.0},\n",
       "   'stacking': True,\n",
       "   'turnover': False,\n",
       "   'stacking_limit': 0.0}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array =  []\n",
    "for data in dataset:\n",
    "    target_array.append(data['filling_space_percent']/100)\n",
    "    del data['filling_space_percent']\n",
    "    del data['density_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_array = []\n",
    "for data in dataset:\n",
    "    source_array_1 = [[],[],[],[],[]]\n",
    "    for box in data['boxes']:\n",
    "        source_array_1[0].append(box['size']['length'])\n",
    "        source_array_1[1].append(box['size']['width'])\n",
    "        source_array_1[2].append(box['size']['height'])\n",
    "        source_array_1[3].append(int(box['stacking']))\n",
    "        source_array_1[4].append(int(box['turnover']))\n",
    "    source_array.append(source_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2849"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = max(map(len, source_array))\n",
    "for arr in source_array:\n",
    "    if (max(map(len, arr)) > length):\n",
    "        length = max(map(len, arr))\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for arr in source_array:\n",
    "    X.append(np.array([xi+[0]*(length-len(xi)) for xi in arr]))\n",
    "\n",
    "source = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(628, 5, 2849)\n",
      "(628,)\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(source).astype(float)\n",
    "Y = np.asarray(target_array).astype(float)\n",
    "\n",
    "normalizer1 = tf.keras.layers.experimental.preprocessing.Normalization(axis=None)\n",
    "normalizer1.adapt(X)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_probability==0.7.0\n",
      "  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n",
      "     -------------------------------------- 981.4/981.4 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from tensorflow_probability==0.7.0) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from tensorflow_probability==0.7.0) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=0.6.1 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from tensorflow_probability==0.7.0) (2.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\liza\\anaconda\\envs\\tf\\lib\\site-packages (from tensorflow_probability==0.7.0) (1.16.0)\n",
      "Installing collected packages: tensorflow_probability\n",
      "  Attempting uninstall: tensorflow_probability\n",
      "    Found existing installation: tensorflow-probability 0.19.0\n",
      "    Uninstalling tensorflow-probability-0.19.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.19.0\n",
      "Successfully installed tensorflow_probability-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow_probability==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a Tensor with unknown first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     18\u001b[0m \u001b[39m# Обучение модели на тренировочных данных\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m history \u001b[39m=\u001b[39m create_bayesian_model(X_test)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Оценка качества модели на тестовых данных\u001b[39;00m\n\u001b[0;32m     22\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m create_bayesian_model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m, in \u001b[0;36mcreate_bayesian_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_bayesian_model\u001b[39m(input_shape):\n\u001b[0;32m      8\u001b[0m   model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m----> 9\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mInputLayer(input_shape\u001b[39m=\u001b[39;49minp),\n\u001b[0;32m     10\u001b[0m     tfp\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDenseFlipout(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     11\u001b[0m     tfp\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDenseFlipout(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     12\u001b[0m     tfp\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDenseFlipout(\u001b[39m1\u001b[39m),\n\u001b[0;32m     13\u001b[0m     tfp\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDistributionLambda(\u001b[39mlambda\u001b[39;00m t: tfp\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mNormal(loc\u001b[39m=\u001b[39mt, scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)),\n\u001b[0;32m     14\u001b[0m     ])\n\u001b[0;32m     15\u001b[0m   negloglik \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m y, rv_y: \u001b[39m-\u001b[39mrv_y\u001b[39m.\u001b[39mlog_prob(y)\n\u001b[0;32m     16\u001b[0m   model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m), loss\u001b[39m=\u001b[39mnegloglik)\n",
      "File \u001b[1;32mc:\\liza\\anaconda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\liza\\anaconda\\envs\\tf\\lib\\site-packages\\keras\\engine\\keras_tensor.py:411\u001b[0m, in \u001b[0;36mKerasTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot iterate over a scalar.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    410\u001b[0m \u001b[39mif\u001b[39;00m shape[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 411\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    412\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot iterate over a Tensor with unknown first dimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[0;32m    414\u001b[0m \u001b[39mreturn\u001b[39;00m _KerasTensorIterator(\u001b[39mself\u001b[39m, shape[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot iterate over a Tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(5, 2849, 1))\n",
    "x=inp\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "R^2 score: -1.4878\n",
      "MSE: 0.1270\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"R^2 score: {:.4f}\".format(r2))\n",
    "print(\"MSE: {:.4f}\".format(mse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
